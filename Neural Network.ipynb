{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMqUKS9QfMAW1Da8D2qXWs7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**https://www.youtube.com/watch?v=Jy4wM2X21u0&list=PLhhyoLH6IjfxeoooqP9rhU3HJIAVAJ3Vz&index=3**"],"metadata":{"id":"pEckWi-Y-0Uc"}},{"cell_type":"markdown","source":["#**FCN (Fully-connected Neural Networks)**"],"metadata":{"id":"zKIenPU79zb7"}},{"cell_type":"markdown","source":["- Imports\n","- Create Fully Connected Layers\n","- Set Device\n","- Hyperparameters\n","- Load Data\n","- Initialize Network\n","- Loss and Optimizer\n","- Train Network\n","- Check accuracy on training & test to see how good our model"],"metadata":{"id":"sjruubPd-noG"}},{"cell_type":"markdown","source":["**Mount Drive**"],"metadata":{"id":"uT-NTxR3982R"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ocfTCd0H-zdw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665394183710,"user_tz":-330,"elapsed":6134,"user":{"displayName":"Gyan Kumar","userId":"04208958827417762560"}},"outputId":"f39976c7-e93e-4060-88f1-cc713e122300"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["**Import Libraries**"],"metadata":{"id":"Rs1iqDtP-EcB"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn   # All neural network modules nn.Linear, nn.conv2d, BatchNorm, Loss functions\n","import torch.optim as optim  # For all optimizations algorithms SGD, Adams etc.\n","import torch.nn.functional as F # All functions that don't have any parameters\n","from torch.utils.data import DataLoader # Gives easier dataset management and creates mini batches\n","import torchvision.datasets as datasets  # Has standard dataset we can import in a nice way\n","import torchvision.transforms as transforms  # Transformations we can perform on our dataset"],"metadata":{"id":"T8p6wnS8-5g-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create Fully Connected Layers\n","class NN(nn.Module):\n","  def __init__(self, input_size, num_classes):\n","    super(NN, self).__init__()\n","    self.fc1 = nn.Linear(input_size, 50)\n","    self.fc2 = nn.Linear(50, num_classes)\n","\n","  def forward(self, x):\n","    x = F.relu(self.fc1(x))\n","    x = self.fc2(x)\n","    return x\n","\n","# Set Device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Hyperparameters\n","input_size = 784\n","num_classes = 10\n","learning_rate = 0.001\n","batch_size = 64\n","num_epochs = 1\n","\n","# Load Data\n","train_dataset = datasets.MNIST('/content/', train=True, transform=transforms.ToTensor(), download=True)\n","train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n","test_dataset = datasets.MNIST('/content/', train=False, transform=transforms.ToTensor(), download=True)\n","test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n","\n","# Initialize Network\n","model = NN(input_size=input_size, num_classes=num_classes).to(device)\n","\n","# Loss and Optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Train Network\n","for epoch in range(num_epochs):\n","  for batch_idx,(data, targets) in enumerate(train_loader):\n","    # Get data to cuda if possible\n","    data = data.to(device=device)\n","    targets = targets.to(device=device)\n","    \n","    # Get to correct shape\n","    #print(data.shape)\n","    data = data.reshape(data.shape[0], -1)\n","\n","    # Forward\n","    scores = model(data)\n","    loss = criterion(scores, targets)\n","\n","    # Backward\n","    optimizer.zero_grad()\n","    loss.backward()\n","\n","    # Gradient Descent or Adam Step\n","    optimizer.step()\n","\n","# Check accuracy on training & test to see how good our model\n","def check_accuracy(loader, model):\n","  if loader.dataset.train:\n","    print(\"Checking accuracy on training data\")\n","  else:\n","    print(\"Checking accuracy on test data\")\n","  \n","  num_correct = 0\n","  num_samples = 0\n","  model.eval()\n","\n","  with torch.no_grad():\n","    for x, y in loader:\n","      x = x.to(device=device)\n","      y = y.to(device=device)\n","      x = x.reshape(x.shape[0], -1)\n","\n","      scores = model(x)\n","      _, predictions = scores.max(1)\n","      num_correct += (predictions == y).sum()\n","      num_samples += predictions.size(0)\n","\n","    #print(f'Got (num_correct)/(num_samples) with accuracy (float(num_correct)/float(num_samples)*100:.2f)')\n","    print(f'Got {num_correct}/{num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n","\n","  model.train()"],"metadata":{"id":"yez6asKm-5jz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["check_accuracy(train_loader, model)\n","check_accuracy(test_loader, model)"],"metadata":{"id":"v_lNyasx-5m2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665394202625,"user_tz":-330,"elapsed":5984,"user":{"displayName":"Gyan Kumar","userId":"04208958827417762560"}},"outputId":"27d7751b-050e-414f-bff9-7dbd7d23de7d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Checking accuracy on training data\n","Got 55832/60000 with accuracy 93.05\n","Checking accuracy on test data\n","Got 9293/10000 with accuracy 92.93\n"]}]}]}